import 'dart:convert';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';
import 'package:supabase_flutter/supabase_flutter.dart';

import 'package:frontend/core/data/api/api_service.dart';
import '../../domain/models/pronunciation_result.dart';

/// å‘éŸ³è¯„ä¼°æœåŠ¡
/// Speech Assessment Service for Azure AI Speech Pronunciation Assessment
///
/// This service uses raw HTTP calls (not Swagger-generated client) as recommended
/// for multipart/form-data endpoints involving file uploads. This provides:
/// - Full control over binary file encoding
/// - Better error debugging
/// - More reliable multipart request handling
class SpeechAssessmentService {
  static final SpeechAssessmentService _instance =
      SpeechAssessmentService._internal();
  factory SpeechAssessmentService() => _instance;
  SpeechAssessmentService._internal();

  /// è·å– API base URL (å¤ç”¨ ApiService çš„ç¯å¢ƒé…ç½®)
  String get _baseUrl => ApiService.baseUrl;

  /// æ„å»ºè¯·æ±‚å¤´ (å¸¦è®¤è¯)
  Map<String, String> _headers() {
    final session = Supabase.instance.client.auth.currentSession;
    final token = session?.accessToken ?? '';

    if (token.isEmpty && kDebugMode) {
      debugPrint('âš ï¸ Warning: No Auth Token available for speech assessment');
    }

    return {'Authorization': 'Bearer $token'};
  }

  /// è¯„ä¼°ç”¨æˆ·å‘éŸ³ (ä»æ–‡ä»¶)
  ///
  /// [audioFile] - å½•éŸ³æ–‡ä»¶ (æ¨è WAV æ ¼å¼, 16kHz, Mono)
  /// [referenceText] - ç”¨æˆ·åº”è¯¥æœ—è¯»çš„å‚è€ƒæ–‡æœ¬
  /// [language] - è¯­è¨€ä»£ç  (é»˜è®¤: en-US)
  /// [enableProsody] - æ˜¯å¦å¯ç”¨è¯­è°ƒè¯„ä¼°
  ///
  /// Returns [PronunciationResult] with detailed phoneme-level feedback
  Future<PronunciationResult> assessPronunciation({
    required File audioFile,
    required String referenceText,
    String language = 'en-US',
    bool enableProsody = true,
  }) async {
    try {
      final uri = Uri.parse('$_baseUrl/speech/assess');

      // æ„å»º multipart è¯·æ±‚
      final request = http.MultipartRequest('POST', uri);

      // æ·»åŠ è®¤è¯å¤´
      request.headers.addAll(_headers());

      // æ·»åŠ è¡¨å•å­—æ®µ
      request.fields['reference_text'] = referenceText;
      request.fields['language'] = language;
      request.fields['enable_prosody'] = enableProsody.toString();

      // æ·»åŠ éŸ³é¢‘æ–‡ä»¶ (WAV format with PCM encoding, required by Azure)
      request.files.add(
        await http.MultipartFile.fromPath(
          'audio',
          audioFile.path,
          filename: 'audio.wav',
          contentType: MediaType('audio', 'wav'),
        ),
      );

      if (kDebugMode) {
        debugPrint(
          '\n\n\nğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ SpeechAssessment: Sending request to $uri',
        );
        debugPrint(
          '   Reference text: "${referenceText.substring(0, referenceText.length.clamp(0, 50))}..."',
        );
        debugPrint('   Language: $language, Prosody: $enableProsody');
      }

      // å‘é€è¯·æ±‚
      final streamedResponse = await request.send();
      final response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body) as Map<String, dynamic>;
        final result = PronunciationResult.fromJson(data);

        if (kDebugMode) {
          debugPrint('âœ… SpeechAssessment: Success');
          debugPrint('   Pronunciation Score: ${result.pronunciationScore}');
          debugPrint('   Accuracy Score: ${result.accuracyScore}');
          debugPrint('   Words analyzed: ${result.wordFeedback.length}');
        }

        return result;
      } else {
        // Log detailed error information
        if (kDebugMode) {
          debugPrint('âŒ SpeechAssessment: HTTP Error');
          debugPrint('   Status Code: ${response.statusCode}');
          debugPrint('   Response Headers: ${response.headers}');
          debugPrint('   Response Body: ${response.body}');
        }

        final errorData = jsonDecode(response.body) as Map<String, dynamic>;
        final errorMessage =
            errorData['error'] ??
            'Failed to assess pronunciation: ${response.statusCode}';

        throw SpeechAssessmentException(
          '$errorMessage (status: ${response.statusCode})',
        );
      }
    } catch (e) {
      if (e is SpeechAssessmentException) rethrow;

      if (kDebugMode) {
        debugPrint('âŒ SpeechAssessment exception: $e');
        debugPrint('   Exception type: ${e.runtimeType}');
      }
      throw SpeechAssessmentException('Error assessing pronunciation: $e');
    }
  }

  /// è¯„ä¼°ç”¨æˆ·å‘éŸ³ (ä»å­—èŠ‚æ•°æ®)
  ///
  /// ç”¨äºå½•éŸ³åç›´æ¥è¯„ä¼°ï¼Œé¿å…ä¸´æ—¶æ–‡ä»¶
  ///
  /// [audioBytes] - éŸ³é¢‘å­—èŠ‚æ•°æ® (æ¨è PCM 16kHz Mono)
  /// [referenceText] - ç”¨æˆ·åº”è¯¥æœ—è¯»çš„å‚è€ƒæ–‡æœ¬
  /// [language] - è¯­è¨€ä»£ç  (é»˜è®¤: en-US)
  /// [enableProsody] - æ˜¯å¦å¯ç”¨è¯­è°ƒè¯„ä¼°
  Future<PronunciationResult> assessPronunciationFromBytes({
    required List<int> audioBytes,
    required String referenceText,
    String language = 'en-US',
    bool enableProsody = true,
  }) async {
    try {
      final uri = Uri.parse('$_baseUrl/speech/assess');

      final request = http.MultipartRequest('POST', uri);

      // æ·»åŠ è®¤è¯å¤´
      request.headers.addAll(_headers());

      // æ·»åŠ è¡¨å•å­—æ®µ
      request.fields['reference_text'] = referenceText;
      request.fields['language'] = language;
      request.fields['enable_prosody'] = enableProsody.toString();

      // ä»å­—èŠ‚åˆ›å»ºæ–‡ä»¶ (WAV format with PCM encoding, required by Azure)
      request.files.add(
        http.MultipartFile.fromBytes(
          'audio',
          audioBytes,
          filename: 'audio.wav',
          contentType: MediaType('audio', 'wav'),
        ),
      );

      if (kDebugMode) {
        debugPrint(
          '\n\n\n\n ğŸ¤ğŸ¤ğŸ¤ SpeechAssessment: Sending ${audioBytes.length} bytes',
        );
        debugPrint(
          '   Reference text: "${referenceText.substring(0, referenceText.length.clamp(0, 50))}..."',
        );
      }

      final streamedResponse = await request.send();
      final response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body) as Map<String, dynamic>;
        return PronunciationResult.fromJson(data);
      } else {
        final errorData = jsonDecode(response.body) as Map<String, dynamic>;
        throw SpeechAssessmentException(
          errorData['error'] ??
              'Failed to assess pronunciation: ${response.statusCode}',
        );
      }
    } catch (e) {
      if (e is SpeechAssessmentException) rethrow;

      if (kDebugMode) {
        debugPrint('âŒ SpeechAssessment error: $e');
      }
      throw SpeechAssessmentException('Error assessing pronunciation: $e');
    }
  }

  /// è¯„ä¼°ç”¨æˆ·å‘éŸ³ (ä»éŸ³é¢‘è·¯å¾„å­—ç¬¦ä¸²)
  ///
  /// ä¾¿æ·æ–¹æ³•ï¼Œæ¥å—è·¯å¾„å­—ç¬¦ä¸²è€Œé File å¯¹è±¡
  Future<PronunciationResult> assessPronunciationFromPath({
    required String audioPath,
    required String referenceText,
    String language = 'en-US',
    bool enableProsody = true,
  }) async {
    return assessPronunciation(
      audioFile: File(audioPath),
      referenceText: referenceText,
      language: language,
      enableProsody: enableProsody,
    );
  }
}

/// å‘éŸ³è¯„ä¼°å¼‚å¸¸
class SpeechAssessmentException implements Exception {
  final String message;

  SpeechAssessmentException(this.message);

  @override
  String toString() => 'SpeechAssessmentException: $message';
}

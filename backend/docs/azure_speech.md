# Azure Speech Pronunciation Assessment API é›†æˆæŒ‡å—

æœ¬æ–‡æ¡£æè¿° TriTalk åç«¯å¦‚ä½•é›†æˆ Azure AI Speech Pronunciation Assessment APIï¼Œå®ç°ç”¨æˆ·å‘éŸ³çš„å®æ—¶è¯„ä¼°ã€‚

## åŠŸèƒ½æ¦‚è¿°

- **éŸ³ç´ çº§å‡†ç¡®åº¦åˆ†æ**: æ¯ä¸ªéŸ³ç´ çš„å‘éŸ³è¯„åˆ† (0-100)
- **å•è¯çº§è¯„ä¼°**: å•è¯å‡†ç¡®åº¦ã€é—æ¼/æ’å…¥/å‘éŸ³é”™è¯¯æ£€æµ‹
- **è¯­è°ƒ/éŸµå¾‹è¯„ä¼°**: Prosody (è¯­è°ƒ) è¯„åˆ†
- **æµåˆ©åº¦æ£€æµ‹**: æ•´ä½“æµåˆ©åº¦è¯„åˆ†
- **Traffic Light UI åé¦ˆ**: æ ¹æ®åˆ†æ•°è‡ªåŠ¨åˆ†ç±»ä¸º perfect/warning/error/missing

## API ç«¯ç‚¹

### POST `/speech/assess`

å‘éŸ³è¯„ä¼°ç«¯ç‚¹ï¼Œæ”¯æŒ multipart/form-data æ ¼å¼ã€‚

#### è¯·æ±‚å‚æ•°

| å‚æ•°             | ç±»å‹    | å¿…å¡« | æè¿°                                        |
| ---------------- | ------- | ---- | ------------------------------------------- |
| `audio`          | File    | âœ…   | éŸ³é¢‘æ–‡ä»¶ (æ¨è: PCM 16bit, 16kHz, Mono WAV) |
| `reference_text` | string  | âœ…   | ç”¨æˆ·åº”è¯¥æœ—è¯»çš„å‚è€ƒæ–‡æœ¬                      |
| `language`       | string  | âŒ   | è¯­è¨€ä»£ç  (é»˜è®¤: "en-US")                    |
| `enable_prosody` | boolean | âŒ   | æ˜¯å¦å¯ç”¨è¯­è°ƒè¯„ä¼° (é»˜è®¤: true)               |

#### å“åº”æ ¼å¼

```json
{
  "recognition_status": "Success",
  "display_text": "The quick brown fox",
  "pronunciation_score": 87.5,
  "accuracy_score": 89.2,
  "fluency_score": 85.0,
  "completeness_score": 100.0,
  "prosody_score": 82.5,
  "words": [
    {
      "word": "the",
      "accuracy_score": 92.3,
      "error_type": "None",
      "phonemes": [
        {
          "phoneme": "Ã°",
          "accuracy_score": 88.5,
          "offset": 0,
          "duration": 50
        },
        {
          "phoneme": "É™",
          "accuracy_score": 96.0,
          "offset": 50,
          "duration": 30
        }
      ]
    }
  ],
  "word_feedback": [
    {
      "text": "the",
      "score": 92.3,
      "level": "perfect",
      "error_type": "None",
      "phonemes": [...]
    }
  ]
}
```

#### Traffic Light è¯„åˆ†é€»è¾‘

| åˆ†æ•°èŒƒå›´ | é”™è¯¯ç±»å‹ | UI ç­‰çº§   | é¢œè‰² |
| -------- | -------- | --------- | ---- |
| > 80     | -        | `perfect` | ç»¿è‰² |
| 60 - 80  | -        | `warning` | é»„è‰² |
| < 60     | -        | `error`   | çº¢è‰² |
| -        | Omission | `missing` | ç°è‰² |

## é…ç½®

### ç¯å¢ƒå˜é‡

åœ¨ Cloudflare Dashboard æˆ– `.dev.vars` ä¸­é…ç½®ï¼š

```bash
AZURE_SPEECH_KEY=your_azure_speech_subscription_key
AZURE_SPEECH_REGION=westus2
```

### è·å– Azure Speech API Key

1. ç™»å½• [Azure Portal](https://portal.azure.com)
2. åˆ›å»º "Cognitive Services" -> "Speech" èµ„æº
3. åœ¨èµ„æºé¡µé¢æ‰¾åˆ° Keys and Endpoint
4. å¤åˆ¶ Key 1 æˆ– Key 2 ä½œä¸º `AZURE_SPEECH_KEY`
5. å¤åˆ¶ Location/Region ä½œä¸º `AZURE_SPEECH_REGION`

## éŸ³é¢‘æ ¼å¼è¦æ±‚

Azure Speech API æ¨èçš„éŸ³é¢‘æ ¼å¼ï¼š

- **ç¼–ç **: PCM (æœªå‹ç¼©)
- **é‡‡æ ·ç‡**: 16kHz
- **ä½æ·±**: 16-bit
- **å£°é“**: Mono (å•å£°é“)
- **æ ¼å¼**: WAV

> ğŸ’¡ æç¤º: å…¶ä»–æ ¼å¼ (å¦‚ mp3, m4a) ä¹Ÿå¯èƒ½è¢«æ¥å—ï¼Œä½† PCM 16kHz Mono WAV æä¾›æœ€ä½³å‡†ç¡®åº¦ã€‚

## å‰ç«¯é›†æˆç¤ºä¾‹

### Flutter æœåŠ¡ç±»å®Œæ•´ç¤ºä¾‹

åŸºäº TriChat `chat_service.dart` çš„ä»£ç æ¨¡å¼ï¼Œä»¥ä¸‹æ˜¯å‘éŸ³è¯„ä¼°æœåŠ¡çš„å®Œæ•´å®ç°ï¼š

```dart
import 'dart:convert';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import '../config/env.dart';
import '../services/auth_service.dart';

/// å‘éŸ³è¯„ä¼°ç»“æœæ¨¡å‹
class PronunciationResult {
  final String recognitionStatus;
  final String displayText;
  final double pronunciationScore;
  final double accuracyScore;
  final double fluencyScore;
  final double completenessScore;
  final double? prosodyScore;
  final List<WordFeedback> wordFeedback;

  PronunciationResult({
    required this.recognitionStatus,
    required this.displayText,
    required this.pronunciationScore,
    required this.accuracyScore,
    required this.fluencyScore,
    required this.completenessScore,
    this.prosodyScore,
    required this.wordFeedback,
  });

  factory PronunciationResult.fromJson(Map<String, dynamic> json) {
    return PronunciationResult(
      recognitionStatus: json['recognition_status'] as String,
      displayText: json['display_text'] as String,
      pronunciationScore: (json['pronunciation_score'] as num).toDouble(),
      accuracyScore: (json['accuracy_score'] as num).toDouble(),
      fluencyScore: (json['fluency_score'] as num).toDouble(),
      completenessScore: (json['completeness_score'] as num).toDouble(),
      prosodyScore: json['prosody_score'] != null
          ? (json['prosody_score'] as num).toDouble()
          : null,
      wordFeedback: (json['word_feedback'] as List<dynamic>)
          .map((w) => WordFeedback.fromJson(w as Map<String, dynamic>))
          .toList(),
    );
  }
}

/// å•è¯åé¦ˆæ¨¡å‹ (Traffic Light ç³»ç»Ÿ)
class WordFeedback {
  final String text;
  final double score;
  final String level; // perfect, warning, error, missing
  final String errorType;
  final List<PhonemeFeedback> phonemes;

  WordFeedback({
    required this.text,
    required this.score,
    required this.level,
    required this.errorType,
    required this.phonemes,
  });

  factory WordFeedback.fromJson(Map<String, dynamic> json) {
    return WordFeedback(
      text: json['text'] as String,
      score: (json['score'] as num).toDouble(),
      level: json['level'] as String,
      errorType: json['error_type'] as String,
      phonemes: (json['phonemes'] as List<dynamic>)
          .map((p) => PhonemeFeedback.fromJson(p as Map<String, dynamic>))
          .toList(),
    );
  }

  /// è·å–å•è¯é¢œè‰² (Traffic Light)
  Color get color {
    switch (level) {
      case 'perfect':
        return Colors.green;
      case 'warning':
        return Colors.orange;
      case 'error':
        return Colors.red;
      case 'missing':
        return Colors.grey;
      default:
        return Colors.black;
    }
  }
}

/// éŸ³ç´ åé¦ˆæ¨¡å‹
class PhonemeFeedback {
  final String phoneme; // IPA éŸ³æ ‡
  final double accuracyScore;
  final int? offset;
  final int? duration;

  PhonemeFeedback({
    required this.phoneme,
    required this.accuracyScore,
    this.offset,
    this.duration,
  });

  factory PhonemeFeedback.fromJson(Map<String, dynamic> json) {
    return PhonemeFeedback(
      phoneme: json['phoneme'] as String,
      accuracyScore: (json['accuracy_score'] as num).toDouble(),
      offset: json['offset'] as int?,
      duration: json['duration'] as int?,
    );
  }
}

/// å‘éŸ³è¯„ä¼°æœåŠ¡
class SpeechAssessmentService {
  final AuthService _authService;

  SpeechAssessmentService({AuthService? authService})
      : _authService = authService ?? AuthService();

  /// æ„å»ºè¯·æ±‚å¤´
  Map<String, String> _headers() {
    final headers = {'Content-Type': 'application/json'};
    final token = _authService.accessToken;
    if (token != null) {
      headers['Authorization'] = 'Bearer $token';
    }
    return headers;
  }

  /// è¯„ä¼°ç”¨æˆ·å‘éŸ³
  ///
  /// [audioFile] - å½•éŸ³æ–‡ä»¶ (æ¨è WAV æ ¼å¼, 16kHz, Mono)
  /// [referenceText] - ç”¨æˆ·åº”è¯¥æœ—è¯»çš„å‚è€ƒæ–‡æœ¬
  /// [language] - è¯­è¨€ä»£ç  (é»˜è®¤: en-US)
  /// [enableProsody] - æ˜¯å¦å¯ç”¨è¯­è°ƒè¯„ä¼°
  Future<PronunciationResult> assessPronunciation({
    required File audioFile,
    required String referenceText,
    String language = 'en-US',
    bool enableProsody = true,
  }) async {
    try {
      final baseUrl = Env.apiBaseUrl;
      final uri = Uri.parse('$baseUrl/speech/assess');

      // æ„å»º multipart è¯·æ±‚
      final request = http.MultipartRequest('POST', uri);

      // æ·»åŠ è®¤è¯å¤´
      final token = _authService.accessToken;
      if (token != null) {
        request.headers['Authorization'] = 'Bearer $token';
      }

      // æ·»åŠ è¡¨å•å­—æ®µ
      request.fields['reference_text'] = referenceText;
      request.fields['language'] = language;
      request.fields['enable_prosody'] = enableProsody.toString();

      // æ·»åŠ éŸ³é¢‘æ–‡ä»¶
      request.files.add(await http.MultipartFile.fromPath(
        'audio',
        audioFile.path,
        filename: 'audio.wav',
      ));

      // å‘é€è¯·æ±‚
      final streamedResponse = await request.send();
      final response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body) as Map<String, dynamic>;
        return PronunciationResult.fromJson(data);
      } else {
        final errorData = jsonDecode(response.body) as Map<String, dynamic>;
        throw Exception(
          errorData['error'] ?? 'Failed to assess pronunciation: ${response.statusCode}',
        );
      }
    } catch (e) {
      if (kDebugMode) {
        debugPrint('SpeechAssessmentService error: $e');
      }
      rethrow;
    }
  }

  /// ä»å­—èŠ‚æ•°æ®è¯„ä¼°å‘éŸ³ (ç”¨äºå½•éŸ³åç›´æ¥è¯„ä¼°)
  Future<PronunciationResult> assessPronunciationFromBytes({
    required List<int> audioBytes,
    required String referenceText,
    String language = 'en-US',
    bool enableProsody = true,
  }) async {
    try {
      final baseUrl = Env.apiBaseUrl;
      final uri = Uri.parse('$baseUrl/speech/assess');

      final request = http.MultipartRequest('POST', uri);

      // æ·»åŠ è®¤è¯å¤´
      final token = _authService.accessToken;
      if (token != null) {
        request.headers['Authorization'] = 'Bearer $token';
      }

      // æ·»åŠ è¡¨å•å­—æ®µ
      request.fields['reference_text'] = referenceText;
      request.fields['language'] = language;
      request.fields['enable_prosody'] = enableProsody.toString();

      // ä»å­—èŠ‚åˆ›å»ºæ–‡ä»¶
      request.files.add(http.MultipartFile.fromBytes(
        'audio',
        audioBytes,
        filename: 'audio.wav',
      ));

      final streamedResponse = await request.send();
      final response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body) as Map<String, dynamic>;
        return PronunciationResult.fromJson(data);
      } else {
        final errorData = jsonDecode(response.body) as Map<String, dynamic>;
        throw Exception(
          errorData['error'] ?? 'Failed to assess pronunciation: ${response.statusCode}',
        );
      }
    } catch (e) {
      if (kDebugMode) {
        debugPrint('SpeechAssessmentService error: $e');
      }
      rethrow;
    }
  }
}
```

### ä½¿ç”¨ç¤ºä¾‹

```dart
// åˆå§‹åŒ–æœåŠ¡
final speechService = SpeechAssessmentService();

// ä»æ–‡ä»¶è¯„ä¼°å‘éŸ³
final result = await speechService.assessPronunciation(
  audioFile: File('/path/to/recording.wav'),
  referenceText: 'The quick brown fox jumps over the lazy dog',
  language: 'en-US',
  enableProsody: true,
);

// æ‰“å°ç»“æœ
print('å‘éŸ³è¯„åˆ†: ${result.pronunciationScore}');
print('å‡†ç¡®åº¦: ${result.accuracyScore}');
print('æµåˆ©åº¦: ${result.fluencyScore}');

// éå†æ¯ä¸ªå•è¯çš„åé¦ˆ
for (final word in result.wordFeedback) {
  print('${word.text}: ${word.score} (${word.level})');

  // å¦‚æœæ˜¯é—®é¢˜å•è¯ï¼Œæ˜¾ç¤ºéŸ³ç´ è¯¦æƒ…
  if (word.level == 'error' || word.level == 'warning') {
    for (final phoneme in word.phonemes) {
      print('  éŸ³ç´ : ${phoneme.phoneme}, è¯„åˆ†: ${phoneme.accuracyScore}');
    }
  }
}
```

### UI ç»„ä»¶å»ºè®®

1. **SpeechBubble ç»„ä»¶**: æ ¹æ® `word_feedback.level` ä¸ºæ¯ä¸ªå•è¯ç€è‰²
2. **CorrectionCard ç»„ä»¶**: ç‚¹å‡»å•è¯æ—¶æ˜¾ç¤ºéŸ³ç´ è¯¦æƒ…
3. **ScoreGauge ç»„ä»¶**: æ˜¾ç¤ºæ•´ä½“ `pronunciation_score`
4. **ProsodyChart ç»„ä»¶**: å¦‚æœéœ€è¦éŸ³é«˜æ›²çº¿ï¼Œä½¿ç”¨ `fl_chart` ç»‘å®š prosody æ•°æ®

### cURL æµ‹è¯•ç¤ºä¾‹

```bash
# æµ‹è¯•å‘éŸ³è¯„ä¼° API
curl -X POST http://localhost:8787/speech/assess \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -F "audio=@/path/to/audio.wav" \
  -F "reference_text=Hello world" \
  -F "language=en-US" \
  -F "enable_prosody=true"
```

## é”™è¯¯å¤„ç†

| é”™è¯¯ä¿¡æ¯                          | åŸå›                   | è§£å†³æ–¹æ¡ˆ                      |
| --------------------------------- | --------------------- | ----------------------------- |
| "Azure Speech is not configured"  | æœªé…ç½® API Key/Region | æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®              |
| "Azure Speech recognition failed" | æ— æ³•è¯†åˆ«è¯­éŸ³          | æ£€æŸ¥éŸ³é¢‘è´¨é‡/æ ¼å¼             |
| "No audio file uploaded"          | æœªä¸Šä¼ éŸ³é¢‘æ–‡ä»¶        | ç¡®ä¿ multipart è¯·æ±‚åŒ…å« audio |
| "Reference text is required"      | æœªæä¾›å‚è€ƒæ–‡æœ¬        | æ·»åŠ  reference_text å­—æ®µ      |

## ç›¸å…³é“¾æ¥

- [Azure Speech Pronunciation Assessment å®˜æ–¹æ–‡æ¡£](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-pronunciation-assessment)
- [Azure Speech REST API å‚è€ƒ](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-speech-to-text-short)
